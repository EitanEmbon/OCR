{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compilación\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: no se puede crear el directorio «build»: El archivo ya existe\n",
      "-- The C compiler identification is GNU 9.4.0\n",
      "-- The CXX compiler identification is GNU 9.4.0\n",
      "-- Check for working C compiler: /usr/bin/cc\n",
      "-- Check for working C compiler: /usr/bin/cc -- works\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++\n",
      "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "Release mode\n",
      "-- Found PythonInterp: /home/eitancho/.pyenv/shims/python (found version \"3.6.5\") \n",
      "-- Found PythonLibs: /home/eitancho/.pyenv/versions/3.6.5/lib/libpython3.6m.a\n",
      "-- pybind11 v2.2.4\n",
      "-- Performing Test HAS_FLTO\n",
      "-- Performing Test HAS_FLTO - Success\n",
      "-- LTO enabled\n",
      "CMAKE_INSTALL_PREFIX=/home/eitancho/Escritorio/tp2_eigen+pybind/tp2\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /home/eitancho/Escritorio/tp2_eigen+pybind/tp2/build\n",
      "\u001b[35m\u001b[1mScanning dependencies of target tp2\u001b[0m\n",
      "[ 10%] \u001b[32mBuilding CXX object CMakeFiles/tp2.dir/src/main.cpp.o\u001b[0m\n",
      "[ 20%] \u001b[32mBuilding CXX object CMakeFiles/tp2.dir/src/knn.cpp.o\u001b[0m\n",
      "[ 30%] \u001b[32mBuilding CXX object CMakeFiles/tp2.dir/src/pca.cpp.o\u001b[0m\n",
      "[ 40%] \u001b[32mBuilding CXX object CMakeFiles/tp2.dir/src/eigen.cpp.o\u001b[0m\n",
      "[ 50%] \u001b[32m\u001b[1mLinking CXX executable tp2\u001b[0m\n",
      "[ 50%] Built target tp2\n",
      "\u001b[35m\u001b[1mScanning dependencies of target metnum\u001b[0m\n",
      "[ 60%] \u001b[32mBuilding CXX object CMakeFiles/metnum.dir/src/metnum.cpp.o\u001b[0m\n",
      "[ 70%] \u001b[32mBuilding CXX object CMakeFiles/metnum.dir/src/knn.cpp.o\u001b[0m\n",
      "[ 80%] \u001b[32mBuilding CXX object CMakeFiles/metnum.dir/src/pca.cpp.o\u001b[0m\n",
      "[ 90%] \u001b[32mBuilding CXX object CMakeFiles/metnum.dir/src/eigen.cpp.o\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX shared module metnum.cpython-36m-x86_64-linux-gnu.so\u001b[0m\n",
      "[100%] Built target metnum\n",
      "\u001b[36mInstall the project...\u001b[0m\n",
      "-- Install configuration: \"Release\"\n",
      "-- Installing: /home/eitancho/Escritorio/tp2_eigen+pybind/tp2/notebooks/metnum.cpython-36m-x86_64-linux-gnu.so\n"
     ]
    }
   ],
   "source": [
    "!cd .. && mkdir build\n",
    "!cd ../build/ && rm -rf *\n",
    "!rm -f *.so\n",
    "!cd ../build && cmake \\\n",
    "  -DPYTHON_EXECUTABLE=\"$(which python)\" \\\n",
    "  -DCMAKE_BUILD_TYPE=Release ..\n",
    "!cd ../build && make install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eitancho/Escritorio/tp2_eigen+pybind/tp2/notebooks\n",
      "Python 3.6.5\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'metnum'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-13d65f1a739d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pwd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'python --version'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmetnum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'metnum'"
     ]
    }
   ],
   "source": [
    "# Verifico la correcta instalación. Si no falla el import está OK\n",
    "!pwd\n",
    "!python --version\n",
    "import metnum\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1998)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K fold configuration y split simple\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "# Retorna el par data/labels a partir de un dataframe\n",
    "def Xypair(dataset):\n",
    "    X = dataset[dataset.columns[1:]].values\n",
    "    y = dataset[\"label\"].values.reshape(-1,1)\n",
    "    return (X,y)\n",
    "\n",
    "# Retorna k splits a partir del dataset (train/test) en pares (data/labels) o (X,y)\n",
    "def Kfoldconfig(dataset, K):\n",
    "    kfold = KFold(K, True, 7)\n",
    "    splits = []\n",
    "    for train, test in kfold.split(dataset):\n",
    "        splits.append((Xypair(dataset.iloc[train]), Xypair(dataset.iloc[test])))\n",
    "    return splits\n",
    "\n",
    "def singlesplit(dataset, limit):\n",
    "    train_data = Xypair(dataset[:int(limit)])\n",
    "    val_data = Xypair(dataset[int(limit):])\n",
    "    return (train_data, val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones para correr los experimentos\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuando los splits son muy chicos o el accuracy es muy malo y no aparecen todos digitos se invalida el F-score para esos labels\n",
    "# Lo siguiente es para evitar el mensaje de warning al calcular el F-score\n",
    "import warnings\n",
    "import sklearn.exceptions\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n",
    "\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def run_KNN(dataset, K, k):\n",
    "    # Definimos los splits del dataset\n",
    "    splits = []\n",
    "    if K == 0:\n",
    "        splits.append(singlesplit(dataset, int(dataset.shape[0] * 0.8)))\n",
    "    else:\n",
    "        splits = Kfoldconfig(dataset, K)\n",
    "    # Para cada split del dataset\n",
    "    m = len(splits)\n",
    "    acc = []\n",
    "    f1 = []\n",
    "    times = []\n",
    "    y_pred = []\n",
    "    for split in splits:\n",
    "        X,y = split[0]\n",
    "        X_val, y_val = split[1]\n",
    "\n",
    "        start = time.clock()\n",
    "\n",
    "        # Predecimos con KNN\n",
    "        clf = metnum.KNNClassifier(k)\n",
    "        clf.fit(X, y)\n",
    "        y_pred = clf.predict(X_val)\n",
    "\n",
    "        end = time.clock()\n",
    "\n",
    "        acc.append(accuracy_score(y_val, y_pred))\n",
    "        f1.append(f1_score(y_val, y_pred, average=\"macro\", labels=np.unique(y_pred)))\n",
    "        times.append(end - start)\n",
    "\n",
    "    return (np.mean(times), np.mean(acc), np.mean(f1), y_pred)\n",
    "\n",
    "def run_KNN_PCA(dataset, K, k, alpha):\n",
    "    # Definimos los splits del dataset\n",
    "    splits = []\n",
    "    if K == 0:\n",
    "        splits.append(singlesplit(dataset, int(dataset.shape[0] * 0.8)))\n",
    "    else:\n",
    "        splits = Kfoldconfig(dataset, K)\n",
    "    # Para cada split del dataset\n",
    "    m = len(splits)\n",
    "    acc = []\n",
    "    f1 = []\n",
    "    times = []\n",
    "    y_pred = []\n",
    "    for split in splits:\n",
    "        X,y = split[0]\n",
    "        X_val, y_val = split[1]\n",
    "        \n",
    "        start = time.clock()\n",
    "\n",
    "        # Generamos un nuevos datasets de dimension alpha de train y de validacion con PCA\n",
    "        pca = metnum.PCA(alpha)\n",
    "        pca.fit(X)\n",
    "        X = pca.transform(X)\n",
    "        X_val = pca.transform(X_val)\n",
    "        \n",
    "        # Predecimos con KNN\n",
    "        clf = metnum.KNNClassifier(k)\n",
    "        clf.fit(X, y)\n",
    "        y_pred = clf.predict(X_val)\n",
    "        \n",
    "        end = time.clock()\n",
    "\n",
    "        acc.append(accuracy_score(y_val, y_pred))\n",
    "        f1.append(f1_score(y_val, y_pred, average=\"weighted\", labels=np.unique(y_pred)))\n",
    "        times.append(end - start)\n",
    "   \n",
    "    return (np.mean(times), np.mean(acc), np.mean(f1), y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_resultado(columnas, filas):\n",
    "    res = pd.DataFrame(filas, columns=columnas)\n",
    "    res.to_csv(\"../results/{}.csv\".format(filas[0][0]), index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargamos los datos\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buscamos valores óptimos con un subconjunto de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/train.csv\")\n",
    "df_30000 = df_train.sample(30000)\n",
    "df_20000 = df_train.sample(20000)\n",
    "df_10000 = df_train.sample(10000)\n",
    "df_5000 = df_train.sample(5000)\n",
    "df_1000 = df_train.sample(1000)\n",
    "df_500 = df_train.sample(500)\n",
    "df_100 = df_train.sample(100)\n",
    "\n",
    "m = df_train.shape[1]\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corremos los experimentos\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "columnas = [\"experimento\", \"metodo\", \"K-folds\", \"k\", \"alpha\", \"tiempo\", \"accuracy\", \"F1-score\", \"prediccion\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN con Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filas = []\n",
    "for K in tqdm(range(2, 10 + 1, 2), desc='Fold loop'):\n",
    "    for k in tqdm(range(1, 50 + 1, 1), desc='k loop'):\n",
    "        res = run_KNN(df_1000, K, k)\n",
    "        filas.append([\"KNN_1000_KFold\", \"KNN\", K, k, 0, res[0], res[1], res[2], res[3]])\n",
    "\n",
    "guardar_resultado(columnas, filas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN + PCA sin Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filas = []\n",
    "# Testeamos distintos valores de alpha para los 3 mejores k encontrados\n",
    "k = 12\n",
    "\n",
    "for alpha in tqdm(range(1, 50, 1), desc='Alpha loop'):\n",
    "    res = run_KNN_PCA(df_1000, 0, k, alpha)\n",
    "    filas.append([\"KNN_k:12_PCA_1000\", \"KNN_PCA\", 0, k, alpha, res[0], res[1], res[2], res[3]])\n",
    "\n",
    "guardar_resultado(columnas, filas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN + PCA con Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filas = []\n",
    "k = 1\n",
    "Ks = (5, 10)\n",
    "for K in tqdm(range(0, len(Ks)), desc='Fold loop'):\n",
    "    for alpha in tqdm(range(1, 30 + 1, 2), desc='Alpha loop'):\n",
    "        res = run_KNN_PCA(df_100, Ks[K], k, alpha)\n",
    "        filas.append([\"KNN_k:5_PCA_KFold\", \"KNN_PCA\", Ks[K], k, alpha, res[0], res[1], res[2], res[3]])\n",
    "\n",
    "guardar_resultado(columnas, filas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset entero k=1 alpha=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "filas = []\n",
    "k = 12\n",
    "alpha = 25\n",
    "res = run_KNN_PCA(df_train, 0, k, alpha)\n",
    "filas.append([\"KNN_k:12_PCA_alpha:25\", \"KNN_PCA\", 0, k, alpha, res[0], res[1], res[2], res[3]])\n",
    "\n",
    "guardar_resultado(columnas, filas)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "499f3562abeebf1eb07a5a780ae9564dd0aa2b485ea426e82266f27a18680ee9"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
